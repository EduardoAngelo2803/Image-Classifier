{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# Definir transformações para os dados de treinamento e validação\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # Removendo o hue\n",
    "        transforms.RandomAffine(degrees=20, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'imagens'\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "patience = 5\n",
    "\n",
    "# Carregar os dados\n",
    "image_datasets = {x: datasets.ImageFolder(root=f\"{data_dir}/{x}\", transform=data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "               for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Carregar o modelo EfficientNet pré-treinado\n",
    "model_ft = models.efficientnet_b0(pretrained=True)\n",
    "num_ftrs = model_ft.classifier[1].in_features\n",
    "model_ft.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(num_ftrs, 1)\n",
    ")\n",
    "\n",
    "# Descongelar mais camadas\n",
    "for param in list(model_ft.parameters())[:-10]:\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model_ft.parameters()), lr=0.001)\n",
    "\n",
    "# Definir o scheduler para reduzir a taxa de aprendizado automaticamente\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "\n",
    "# Função para treinar o modelo com early stopping\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, patience=5):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.sigmoid(outputs).round()\n",
    "                    loss = criterion(outputs, labels.unsqueeze(1))\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.unsqueeze(1).data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Salvar o modelo se a acurácia na validação melhorar\n",
    "            if phase == 'val':\n",
    "                scheduler.step(epoch_loss)\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer, scheduler, num_epochs=num_epochs, patience=patience)\n",
    "\n",
    "# Salvando o modelo treinado\n",
    "torch.save(model_ft.state_dict(), 'modelo_camisas_sport_nautico.pth')\n",
    "torch.save(optimizer.state_dict(), 'optimizer_camisas_sport_nautico.pth')\n",
    "\n",
    "# Função para calcular e exibir métricas de avaliação\n",
    "def evaluate_model(model, dataloaders, dataset_sizes):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders['val']:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.sigmoid(outputs).round()\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "    print('\\nClassification Report:')\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "    # Plot da matriz de confusão\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Avaliar o modelo treinado\n",
    "evaluate_model(model_ft, dataloaders, dataset_sizes)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
